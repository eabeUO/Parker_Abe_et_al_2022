{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO3DUuI1KanKUmqK7HidgF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliottabe/pytorchGLM/blob/main/pytorchGLM_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Modules and repo"
      ],
      "metadata": {
        "id": "XutIZFDufnX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !git clone https://github.com/elliottabe/pytorchGLM.git"
      ],
      "metadata": {
        "id": "19ZFnSUXbsXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./pytorchGLM/requirements.txt"
      ],
      "metadata": {
        "id": "zxoWenNwcydQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5VDfJClbQzZ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/elliottabe/pytorchGLM.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U matplotlib"
      ],
      "metadata": {
        "id": "pA-n83w7cAQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Modules"
      ],
      "metadata": {
        "id": "5tZt3rCRftKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray import air\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "##### Custom package #####\n",
        "import pytorchGLM as pglm\n",
        "from pytorchGLM.main.training import train_network\n",
        "\n",
        "##### Plotting settings ######\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams.update({'font.size':         10,\n",
        "                     'axes.linewidth':    2,\n",
        "                     'xtick.major.size':  3,\n",
        "                     'xtick.major.width': 2,\n",
        "                     'ytick.major.size':  3,\n",
        "                     'ytick.major.width': 2,\n",
        "                     'axes.spines.right': False,\n",
        "                     'axes.spines.top':   False,\n",
        "                     'pdf.fonttype':      42,\n",
        "                     'xtick.labelsize':   10,\n",
        "                     'ytick.labelsize':   10,\n",
        "                     'figure.facecolor': 'white'\n",
        "\n",
        "                    })\n"
      ],
      "metadata": {
        "id": "TxLvCCB7cAZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = pglm.arg_parser(jupyter=True)\n",
        "args"
      ],
      "metadata": {
        "id": "jHVErh_Lb07h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_BaseModel_params(args,exp_dir_name='Testing',ModelID=0,nKfold=0,debug=False):\n",
        "    \"\"\" Load parameter dictionary for custom BaseModel network. Minimal implementation \n",
        "        adabpting to custom datasets\n",
        "\n",
        "    Args:\n",
        "        args (dict): Argument dictionary \n",
        "        exp_dir_name (str): name of experiment. \n",
        "        ModelID (int, optional): Model Identification number. Defaults to 0.\n",
        "        exp_dir_name (str, optional): Optional experiment directory name if using own data. Defaults to None.\n",
        "        nKfold (int, optional): Kfold number for versioning. Defaults to 0.\n",
        "        debug (bool, optional): debug=True does not create experiment directories. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        params (dict): dictionary of parameters\n",
        "        exp (obj): Test_tube object for organizing files and tensorboard\n",
        "    \"\"\"\n",
        "    import yaml\n",
        "    from pathlib import Path\n",
        "    from test_tube import Experiment\n",
        "    \n",
        "    ##### Create directories and paths #####\n",
        "    date_ani2 = '_'.join(args['date_ani'].split('/'))\n",
        "    data_dir = Path(args['data_dir']).expanduser() / args['date_ani'] / args['stim_cond'] \n",
        "    base_dir = Path(args['base_dir']).expanduser()\n",
        "    save_dir = (base_dir / args['date_ani'] / args['stim_cond'])\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ##### Set up test_tube versioning #####\n",
        "    exp = Experiment(name='ModelID{}'.format(ModelID),\n",
        "                        save_dir=save_dir / exp_dir_name, \n",
        "                        debug=debug,\n",
        "                        version=nKfold)\n",
        "\n",
        "    save_model = exp.save_dir / exp.name / 'version_{}'.format(nKfold)\n",
        "\n",
        "    params = {\n",
        "        ##### Data Parameters #####\n",
        "        'data_dir':                 data_dir,\n",
        "        'base_dir':                 base_dir,\n",
        "        'exp_name_base':            base_dir.name,\n",
        "        'stim_cond':                args['stim_cond'],\n",
        "        'save_dir':                 save_dir,\n",
        "        'exp_name':                 exp.save_dir.name,\n",
        "        'save_model':               save_model,\n",
        "        'date_ani2':                date_ani2,\n",
        "        'model_dt':                 args['model_dt'],\n",
        "        ##### Model Parameters #####\n",
        "        'ModelID':                  ModelID,\n",
        "        'lag_list':                 [0], # List of which timesteps to include in model fit\n",
        "        'Nepochs':                  args['Nepochs'],\n",
        "        'Kfold':                    args['Kfold'],\n",
        "        'NoL1':                     args['NoL1'],\n",
        "        'NoL2':                     args['NoL2'],\n",
        "        'initW':                    'zero',\n",
        "        'train_shifter':            False,\n",
        "        'model_type':               'pytorchGLM_custom', # For naming files\n",
        "    }\n",
        "\n",
        "    params['nt_glm_lag']=len(params['lag_list']) # number of timesteps for model fits\n",
        "    params['data_name'] = '_'.join([params['date_ani2'],params['stim_cond']])\n",
        "    \n",
        "    ##### Saves yaml of parameters #####\n",
        "    if debug==False:\n",
        "        params2=params.copy()\n",
        "        for key in params2.keys():\n",
        "            if isinstance(params2[key], Path):\n",
        "                params2[key]=params2[key].as_posix()\n",
        "\n",
        "        pfile_path = save_model / 'model_params.yaml'\n",
        "        with open(pfile_path, 'w') as file:\n",
        "            doc = yaml.dump(params2, file, sort_keys=True)\n",
        "\n",
        "    return params, exp\n",
        "\n",
        "\n",
        "def initialize_GP_inputs(Npats,length_scale,batch_size,Nx_low,Nx,Ny_star,Nr,seed=42,multi_input=False,pytorch=True):\n",
        "    from sklearn.gaussian_process.kernels import RBF\n",
        "\n",
        "    ##### Set random seed #####\n",
        "    np.random.seed(seed+1)\n",
        "    torch.manual_seed(seed+1)\n",
        "    ##### Initialize RBF kernels #####\n",
        "    rbf = RBF(length_scale=length_scale)\n",
        "    genX = np.arange(Npats)[:,np.newaxis]\n",
        "    genY = np.arange(Npats)[:,np.newaxis]\n",
        "    Kx = rbf(genX,genX)\n",
        "    Ky = rbf(genY,genY)\n",
        "    if multi_input:\n",
        "        ##### Initialize inputs #####\n",
        "        x_low0 = torch.transpose(torch.from_numpy(np.random.multivariate_normal(np.zeros(Npats), Kx,size=(batch_size,Nx_low))),2,1).float()\n",
        "        x_low1 = torch.transpose(torch.from_numpy(np.random.multivariate_normal(np.zeros(Npats), Kx,size=(batch_size,Nx_low))),2,1).float()\n",
        "        x_expand = torch.randn(size=(batch_size,Nx_low,Nx)).float()\n",
        "        x0 = torch.bmm(x_low0,x_expand)\n",
        "        x1 = torch.bmm(x_low1,x_expand)\n",
        "        x_all = torch.stack((x0,x1),dim=1).float()\n",
        "        ##### Initialize target patterns #####\n",
        "        y_all = torch.transpose(torch.from_numpy(np.random.multivariate_normal(np.zeros(Npats), Ky,size=(1,Ny_star,Nr))),3,2)\n",
        "        y_all = ((y_all/torch.max(torch.max(torch.abs(y_all),dim=1,keepdim=True)[0],dim=2,keepdim=True)[0]).repeat(batch_size,1,1,1))\n",
        "    else:\n",
        "        ##### Initialize inputs #####\n",
        "        x_low0 = torch.transpose(torch.from_numpy(np.random.multivariate_normal(np.zeros(Npats), Kx,size=(batch_size,Nx_low))),2,1).float()\n",
        "        x_expand = torch.randn(size=(batch_size,Nx_low,Nx)).float()\n",
        "        x_all = torch.bmm(x_low0,x_expand)#.numpy()\n",
        "        # x_all = torch.from_numpy((x_all - np.nanmean(x_all,axis=0))/np.nanstd(x_all,axis=0)).float()\n",
        "        ##### Initialize target patterns #####\n",
        "        y_all = torch.from_numpy(np.random.multivariate_normal(np.zeros(Npats), Ky,size=(1,Nr)))\n",
        "        y_all = torch.transpose((y_all/torch.max(torch.max(torch.abs(y_all),dim=1,keepdim=True)[0],dim=2,keepdim=True)[0]).repeat(batch_size,1,1),-1,-2)\n",
        "\n",
        "    if pytorch:\n",
        "        x_all = x_all.float()\n",
        "        y_all = y_all.float()\n",
        "    else:\n",
        "        x_all = x_all.float().numpy()\n",
        "        y_all = y_all.float().numpy()\n",
        "\n",
        "    return x_all, y_all\n"
      ],
      "metadata": {
        "id": "XyoncIy6dDTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input arguments\n",
        "args = pglm.arg_parser(jupyter=True)\n",
        "\n",
        "##### Modify default argments if needed #####\n",
        "args['base_dir']        = './Testing'\n",
        "args['fig_dir']         = './FigTesting'\n",
        "args['data_dir']        = './'\n",
        "args['date_ani']        = '011523/TestAni'\n",
        "args['stim_cond']       = 'Control'\n",
        "args['Nepochs']         = 50\n",
        "args['NoL1']            = True\n",
        "args['NoL2']            = False\n",
        "args['model_dt']        = 0\n",
        "\n",
        "params, exp = load_BaseModel_params(args=args,exp_dir_name='CustomData',ModelID=0)"
      ],
      "metadata": {
        "id": "LSjLrCWvdFqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "seed = 2\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "##### Generating data #####\n",
        "x_all,y_all = initialize_GP_inputs(Npats=1000,length_scale=5,batch_size=1,Nx_low=2,Nx=100,Ny_star=2,Nr=10,pytorch=True)\n",
        "x_all, y_all = x_all.squeeze(),y_all.squeeze()\n",
        "y_all = (y_all+1)/2\n",
        "x_all = (x_all - np.nanmean(x_all,axis=0))/np.nanstd(x_all,axis=0)\n",
        "\n",
        "##### Train/Test Splits ####\n",
        "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
        "frac = 0.1\n",
        "nT = x_all.shape[0]\n",
        "groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
        "train_idx, test_idx = next(iter(gss.split(np.arange(x_all.shape[0]), groups=groups)))\n",
        "# train_idx, test_idx = torch.from_numpy(train_idx), torch.from_numpy(test_idx)\n",
        "xtr,xte = x_all[train_idx], x_all[test_idx]\n",
        "xtr_pos,xte_pos = torch.zeros_like(xtr).float(),torch.zeros_like(xte).float()\n",
        "ytr,yte = y_all[train_idx], y_all[test_idx]\n",
        "\n",
        "print('X:',xtr.shape,'Xpos:',xtr_pos.shape,'y:',ytr.shape)\n",
        "print('X:',xte.shape,'Xpos:',xte_pos.shape,'y:',yte.shape)\n",
        "params['nk'] = xtr.shape[-1]\n",
        "params['Ncells'] = ytr.shape[-1]\n",
        "meanbias = torch.mean(y_all,dim=0)\n",
        "\n",
        "xtr, xte, xtr_pos, xte_pos, ytr, yte, meanbias=xtr.to(device), xte.to(device), xtr_pos.to(device), xte_pos.to(device), ytr.to(device), yte.to(device), meanbias.to(device)\n",
        "datasets = {\n",
        "            'xtr':xtr,\n",
        "            'xte':xte,\n",
        "            'xtr_pos':xtr_pos,\n",
        "            'xte_pos':xte_pos,\n",
        "            'ytr':ytr,\n",
        "            'yte':yte,\n",
        "            'meanbias':meanbias,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Irq9vzpVdFs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params['initW'] = 'normal' #'zero' # 'normal'\n",
        "params['optimizer'] = 'sgd'\n",
        "network_config,initial_params = pglm.make_network_config(params,single_trial=0,custom=True)\n",
        "network_config['lr_w'] = .001\n",
        "network_config['lr_b'] = .1"
      ],
      "metadata": {
        "id": "4qIeuyWFdFvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tloss_trace,vloss_trace,model,optimizer = train_network(network_config,**datasets, params=params,filename=None)"
      ],
      "metadata": {
        "id": "IcSPlyYgdFxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Make prediction #####\n",
        "yhat = model(xte.to(device),xte_pos.to(device)).detach().cpu().numpy().squeeze()\n",
        "yt = yte.cpu().detach().numpy().squeeze()"
      ],
      "metadata": {
        "id": "5js0N3YDdFzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpl.__version__"
      ],
      "metadata": {
        "id": "bj0wV59edhlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(10,4))\n",
        "ax = axs[0]\n",
        "cmap = pglm.discrete_cmap(vloss_trace.shape[-1],'jet')\n",
        "for cell in range(vloss_trace.shape[-1]):\n",
        "    ax.plot(vloss_trace[:,cell],c=cmap(cell))\n",
        "ax.set_xlabel('iteration')\n",
        "ax.set_ylabel('loss')\n",
        "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=0, vmax=vloss_trace.shape[-1]))\n",
        "cbar = fig.colorbar(sm,ax=ax,format=None,shrink=0.7,pad=0.01)\n",
        "cbar.outline.set_linewidth(1)\n",
        "cbar.set_label('output dim')\n",
        "cbar.ax.tick_params(labelsize=12, width=1,direction='in')\n",
        "\n",
        "ncell = 0\n",
        "ax = axs[1]\n",
        "ax.plot(yt[:,ncell],c='k',label='actual')\n",
        "ax.plot(yhat[:,ncell],c='r',label='predicted')\n",
        "ax.set_xlabel('time')\n",
        "ax.set_ylabel('activity')\n",
        "ax.set_title('cc={:.03}'.format(np.corrcoef(yhat[:,ncell],yt[:,ncell])[1,0]))\n",
        "ax.legend(labelcolor='linecolor',fontsize=10,ncol=1, markerscale=0, handlelength=0, handletextpad=0,loc=\"upper left\",frameon=False, bbox_to_anchor=(.8, 1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "llhJM0a8dF1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "x_all2,y_all2 = initialize_GP_inputs(Npats=1000,length_scale=5,batch_size=1,Nx_low=2,Nx=100,Ny_star=2,Nr=50,pytorch=False)\n",
        "x_all2, y_all2 = x_all2.squeeze(),y_all2.squeeze()\n",
        "y_all2 = (y_all2+1)/2\n",
        "x_all2 = x_all2/np.max(np.abs(x_all2))\n",
        "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
        "frac = 0.1\n",
        "nT = x_all2.shape[0]\n",
        "groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
        "train_idx, test_idx = next(iter(gss.split(np.arange(x_all2.shape[0]), groups=groups)))\n",
        "# train_idx, test_idx = torch.from_numpy(train_idx), torch.from_numpy(test_idx)\n",
        "xtr2,xte2 = x_all2[train_idx], x_all2[test_idx]\n",
        "xtr_pos2,xte_pos2 = np.zeros_like(xtr2),np.zeros_like(xte2)\n",
        "ytr2,yte2 = y_all2[train_idx], y_all2[test_idx]\n",
        "\n",
        "\n",
        "l1 = LinearRegression()\n",
        "l1.fit(xtr2,ytr2)\n",
        "yhat2 = l1.predict(xte2)\n",
        "print('cc=',np.corrcoef(yhat2[:,ncell],yte2[:,ncell])[0,1])"
      ],
      "metadata": {
        "id": "wDCD91p3dF31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,1,figsize=(4,4))\n",
        "ax = axs\n",
        "ax.plot(yt[:,ncell],c='k',label='actual')\n",
        "ax.plot(yhat2[:,ncell],c='r',label='predicted')\n",
        "ax.legend(fontsize=10,ncol=1,labelcolor='linecolor', markerscale=0, handlelength=0, handletextpad=0,loc=\"upper left\",frameon=False, bbox_to_anchor=(.8, 1))\n",
        "ax.set_xlabel('time')\n",
        "ax.set_ylabel('activity')\n",
        "ax.set_title('cc={:.03}'.format(np.corrcoef(yhat2[:,ncell],yt[:,ncell])[1,0]))\n"
      ],
      "metadata": {
        "id": "W4S6flxvdT6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TbBH6UF3dT8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ray Tune Training: Parallel Cross Validation\n",
        "For details about Ray Tune see: https://docs.ray.io/en/latest/tune/key-concepts.html"
      ],
      "metadata": {
        "id": "gKINkIJfeos4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "from ray.air import session\n",
        "from ray.tune.search import ConcurrencyLimiter\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from hyperopt import hp"
      ],
      "metadata": {
        "id": "5u5XNaZWepGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input arguments\n",
        "args = pglm.arg_parser(jupyter=True)\n",
        "\n",
        "##### Modify default argments if needed #####\n",
        "args['base_dir']        = './Testing'\n",
        "args['fig_dir']         = './FigTesting'\n",
        "args['data_dir']        = './'\n",
        "args['date_ani']        = '011523/TestAni'\n",
        "args['stim_cond']       = 'Control'\n",
        "args['Nepochs']         = 50\n",
        "args['NoL1']            = True\n",
        "args['NoL2']            = True\n",
        "args['model_dt']        = 0\n",
        "\n",
        "params, exp = load_BaseModel_params(args=args,exp_dir_name='CustomData',ModelID=0)\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "##### Generating data #####\n",
        "x_all,y_all = initialize_GP_inputs(Npats=1000,length_scale=5,batch_size=1,Nx_low=2,Nx=100,Ny_star=2,Nr=10,pytorch=True)\n",
        "x_all, y_all = x_all.squeeze(),y_all.squeeze()\n",
        "y_all = (y_all+1)/2\n",
        "x_all = (x_all - np.nanmean(x_all,axis=0))/np.nanstd(x_all,axis=0)\n",
        "\n",
        "##### Train/Test Splits ####\n",
        "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
        "frac = 0.1\n",
        "nT = x_all.shape[0]\n",
        "groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
        "train_idx, test_idx = next(iter(gss.split(np.arange(x_all.shape[0]), groups=groups)))\n",
        "# train_idx, test_idx = torch.from_numpy(train_idx), torch.from_numpy(test_idx)\n",
        "xtr,xte = x_all[train_idx], x_all[test_idx]\n",
        "xtr_pos,xte_pos = torch.zeros_like(xtr).float(),torch.zeros_like(xte).float()\n",
        "ytr,yte = y_all[train_idx], y_all[test_idx]\n",
        "\n",
        "print('X:',xtr.shape,'Xpos:',xtr_pos.shape,'y:',ytr.shape)\n",
        "print('X:',xte.shape,'Xpos:',xte_pos.shape,'y:',yte.shape)\n",
        "\n",
        "params['nk'] = xtr.shape[-1]\n",
        "params['Ncells'] = ytr.shape[-1]\n",
        "meanbias = torch.mean(y_all,dim=0)\n",
        "xtr, xte, xtr_pos, xte_pos, ytr, yte, meanbias=xtr.to(device), xte.to(device), xtr_pos.to(device), xte_pos.to(device), ytr.to(device), yte.to(device), meanbias.to(device)\n",
        "datasets = {\n",
        "            'xtr':xtr,\n",
        "            'xte':xte,\n",
        "            'xtr_pos':xtr_pos,\n",
        "            'xte_pos':xte_pos,\n",
        "            'ytr':ytr,\n",
        "            'yte':yte,\n",
        "            'meanbias':meanbias,\n",
        "        }\n",
        "\n",
        "params['initW'] = 'normal' #'zero' # 'normal'\n",
        "params['optimizer'] = 'sgd'\n",
        "network_config, initial_params = pglm.make_network_config(params,custom=True)\n",
        "network_config['lr_w'] = tune.loguniform(1e-4, 1e-2)\n",
        "network_config['lr_b'] = tune.loguniform(1e-2, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA_XE-2Oeqve",
        "outputId": "cd87f79f-e16d-4cf1-d058-9fc924cf8bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: torch.Size([800, 100]) Xpos: torch.Size([800, 100]) y: torch.Size([800, 10])\n",
            "X: torch.Size([200, 100]) Xpos: torch.Size([200, 100]) y: torch.Size([200, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`network_config` contains the key parameters for the network and this is where we can choose which hyperparameters to optimize. In this example, we will optimize the learning rate of the weights and bias of the network to get the best fit. "
      ],
      "metadata": {
        "id": "hBQE9lsKfNr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_params = [\n",
        "    {\"lr_w\": 0.001,\"lr_b\": 0.1, },\n",
        "]\n",
        "algo = HyperOptSearch(points_to_evaluate=initial_params)\n",
        "algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
        "num_samples = 10"
      ],
      "metadata": {
        "id": "OAtLZpDjfLS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ray.init(ignore_reinit_error=True,include_dashboard=True)\n",
        "\n",
        "sync_config = tune.SyncConfig()  # the default mode is to use use rsync\n",
        "tuner = tune.Tuner(\n",
        "    tune.with_resources(\n",
        "        tune.with_parameters(train_network,**datasets, params=params),\n",
        "        resources={\"cpu\": 2, \"gpu\": .5}),\n",
        "    tune_config=tune.TuneConfig(metric=\"avg_loss\",mode=\"min\",search_alg=algo,num_samples=num_samples),\n",
        "    param_space=network_config,\n",
        "    run_config=air.RunConfig(local_dir=params['save_model'], name=\"NetworkAnalysis\",sync_config=sync_config,verbose=2)\n",
        ")\n",
        "results = tuner.fit()\n",
        "\n",
        "best_result = results.get_best_result(\"avg_loss\", \"min\")\n",
        "\n",
        "print(\"Best trial config: {}\".format(best_result.config))\n",
        "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"avg_loss\"]))\n",
        "##### Get experiment dataframe and best network\n",
        "df = results.get_dataframe()\n",
        "best_network = list(params['save_model'].rglob('*{}.pt'.format(best_result.metrics['trial_id'])))[0]\n",
        "\n",
        "##### Save experiment data and save best network as h5 #####\n",
        "exp_filename = '_'.join([params['model_type'],params['data_name']]) + 'experiment_data.h5'\n",
        "exp_best_dict = {'best_network':best_network,'trial_id':best_result.metrics['trial_id'],'best_config':best_result.config}\n",
        "pglm.h5store(params['save_model'] / ('NetworkAnalysis/{}'.format(exp_filename)), df, **exp_best_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "A2AwpUyVfLVO",
        "outputId": "edc49f56-bace-45cd-c649-0105013397fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-01-18 20:06:41,052\tINFO worker.py:1538 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2023-01-18 20:06:50</td></tr>\n",
              "<tr><td>Running for: </td><td>00:00:07.74        </td></tr>\n",
              "<tr><td>Memory:      </td><td>6.7/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.25 GiB heap, 0.0/3.63 GiB objects (0.0/1.0 accelerator_type:T4)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name            </th><th>status    </th><th>loc             </th><th>L1_alpha  </th><th>L1_alpha_m  </th><th style=\"text-align: right;\">  L2_lambda</th><th style=\"text-align: right;\">  L2_lambda_m</th><th style=\"text-align: right;\">  Ncells</th><th style=\"text-align: right;\">  in_features</th><th>initW  </th><th style=\"text-align: right;\">     lr_b</th><th style=\"text-align: right;\">  lr_m</th><th style=\"text-align: right;\">       lr_w</th><th>optimizer  </th><th>single_trial  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  avg_loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_network_b261ef4b</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.1      </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.001      </td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       2.41895  </td><td style=\"text-align: right;\"> 0.0332593</td></tr>\n",
              "<tr><td>train_network_6992a758</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.075306 </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.00156192 </td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.075006 </td><td style=\"text-align: right;\"> 0.072454 </td></tr>\n",
              "<tr><td>train_network_db66151e</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.0939145</td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.000843987</td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0829155</td><td style=\"text-align: right;\"> 0.0574819</td></tr>\n",
              "<tr><td>train_network_e9d7976b</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.210673 </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.000112121</td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0814035</td><td style=\"text-align: right;\"> 0.021464 </td></tr>\n",
              "<tr><td>train_network_db7e7209</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.618516 </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.00563138 </td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0746589</td><td style=\"text-align: right;\"> 0.0156099</td></tr>\n",
              "<tr><td>train_network_88477952</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.0127561</td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.000139807</td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0776393</td><td style=\"text-align: right;\"> 0.188322 </td></tr>\n",
              "<tr><td>train_network_3059cbcd</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.114416 </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.00151056 </td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0759051</td><td style=\"text-align: right;\"> 0.0357674</td></tr>\n",
              "<tr><td>train_network_63899a89</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.365816 </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.000423115</td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.077414 </td><td style=\"text-align: right;\"> 0.0234202</td></tr>\n",
              "<tr><td>train_network_1479d1d7</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.0242004</td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.00579427 </td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.068208 </td><td style=\"text-align: right;\"> 0.185522 </td></tr>\n",
              "<tr><td>train_network_ffb0b1f2</td><td>TERMINATED</td><td>172.28.0.12:4676</td><td>          </td><td>            </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">          100</td><td>normal </td><td style=\"text-align: right;\">0.338098 </td><td style=\"text-align: right;\"> 0.001</td><td style=\"text-align: right;\">0.00650291 </td><td>sgd        </td><td>              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.068572 </td><td style=\"text-align: right;\"> 0.044061 </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name            </th><th style=\"text-align: right;\">  avg_loss</th><th>should_checkpoint  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_network_1479d1d7</td><td style=\"text-align: right;\"> 0.185522 </td><td>True               </td></tr>\n",
              "<tr><td>train_network_3059cbcd</td><td style=\"text-align: right;\"> 0.0357674</td><td>True               </td></tr>\n",
              "<tr><td>train_network_63899a89</td><td style=\"text-align: right;\"> 0.0234202</td><td>True               </td></tr>\n",
              "<tr><td>train_network_6992a758</td><td style=\"text-align: right;\"> 0.072454 </td><td>True               </td></tr>\n",
              "<tr><td>train_network_88477952</td><td style=\"text-align: right;\"> 0.188322 </td><td>True               </td></tr>\n",
              "<tr><td>train_network_b261ef4b</td><td style=\"text-align: right;\"> 0.0332593</td><td>True               </td></tr>\n",
              "<tr><td>train_network_db66151e</td><td style=\"text-align: right;\"> 0.0574819</td><td>True               </td></tr>\n",
              "<tr><td>train_network_db7e7209</td><td style=\"text-align: right;\"> 0.0156099</td><td>True               </td></tr>\n",
              "<tr><td>train_network_e9d7976b</td><td style=\"text-align: right;\"> 0.021464 </td><td>True               </td></tr>\n",
              "<tr><td>train_network_ffb0b1f2</td><td style=\"text-align: right;\"> 0.044061 </td><td>True               </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n",
            "\u001b[2m\u001b[36m(train_network pid=4676)\u001b[0m Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-01-18 20:06:50,716\tINFO tune.py:762 -- Total run time: 8.07 seconds (7.72 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial config: {'in_features': 100, 'Ncells': 10, 'initW': 'normal', 'optimizer': 'sgd', 'lr_w': 0.005631375559768411, 'lr_b': 0.6185158493997125, 'lr_m': 0.001, 'single_trial': None, 'L1_alpha': None, 'L1_alpha_m': None, 'L2_lambda': 0, 'L2_lambda_m': 0}\n",
            "Best trial final validation loss: 0.015609866008162498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_eval(best_network,network_config,params,xte,xte_pos,yte,device='cpu'):\n",
        "    \"\"\"Evaluates ray tune experiment and hyperparameter search\n",
        "\n",
        "    Args:\n",
        "        best_network (str): path to best network model '.pt' file\n",
        "        network_config (dict): network_config for best network\n",
        "        params (dict): key parameters dictionary\n",
        "        xte (Tensor): test input data \n",
        "        xte_pos (Tensor): test additional input data\n",
        "        yte (Tensor): target test data\n",
        "        device (str, optional): device to load data onto. Defaults to 'cpu'.\n",
        "    \"\"\"\n",
        "    import pytorchGLM.Utils.io_dict_to_hdf5 as ioh5\n",
        "    from pytorchGLM.main.models import model_wrapper,BaseModel\n",
        "\n",
        "    ##### Load best network from saved ray experiment ######\n",
        "    state_dict, _ = torch.load(best_network,map_location='cpu')\n",
        "    model = model_wrapper((network_config,BaseModel))\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "\n",
        "    ##### Load data into device and predict test set ######\n",
        "    xte, xte_pos, yte = xte.to(device), xte_pos.to(device), yte.to(device)\n",
        "    with torch.no_grad():\n",
        "        yhat = model(xte,xte_pos)\n",
        "\n",
        "    ##### Smooth Firing rates and save ######\n",
        "    actual_smooth = yte.detach().cpu().numpy()\n",
        "    pred_smooth = yhat.detach().cpu().numpy()\n",
        "    cc_test = np.array([(np.corrcoef(pred_smooth[:,celln],actual_smooth[:,celln])[0, 1]) for celln in range(pred_smooth.shape[1])])\n",
        "    \n",
        "    GLM_Dict = {\n",
        "        'actual_smooth': actual_smooth,\n",
        "        'pred_smooth': pred_smooth,\n",
        "        'cc_test': cc_test,\n",
        "        }\n",
        "\n",
        "    for key in state_dict.keys():\n",
        "        GLM_Dict[key]  = state_dict[key].cpu().numpy()\n",
        "\n",
        "    model_name = '{}_ModelID{:d}_dt{:03d}_T{:02d}_NB{}_Best.h5'.format(params['model_type'], params['ModelID'],int(params['model_dt']*1000), params['nt_glm_lag'], params['Nepochs'])\n",
        "    ioh5.save(params['save_model']/model_name,GLM_Dict)\n"
      ],
      "metadata": {
        "id": "M5PpJz8jfLXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_eval(best_network,network_config,params,xte,xte_pos,yte,device='cpu')"
      ],
      "metadata": {
        "id": "MTC1HrnRfLZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_filename = list((params['save_model']/'NetworkAnalysis').rglob('*experiment_data.h5'))[0]\n",
        "df,meta_data = pglm.h5load(exp_filename)\n",
        "best_network=meta_data['best_network']\n",
        "best_config = meta_data['best_config']"
      ],
      "metadata": {
        "id": "2b-Nako-fTtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorchGLM.Utils.io_dict_to_hdf5 as ioh5\n",
        "model_name = '{}_ModelID{:d}_dt{:03d}_T{:02d}_NB{}_Best.h5'.format(params['model_type'], params['ModelID'],int(params['model_dt']*1000), params['nt_glm_lag'], params['Nepochs'])\n",
        "GLM_Data = ioh5.load(params['save_model']/model_name)"
      ],
      "metadata": {
        "id": "7Op40XvmfTvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLM_Data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqs0w2Y0fT0U",
        "outputId": "cc197c57-760a-4e07-c15e-30000be4aa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Cell_NN.0.bias', 'Cell_NN.0.weight', 'actual_smooth', 'cc_test', 'pred_smooth'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "za8kIBbPfT2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ray\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import warnings \n",
    "import argparse\n",
    "import yaml\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import xarray as xr\n",
    "\n",
    "from ray import tune\n",
    "from ray import air\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from filelock import FileLock\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from typing import Tuple\n",
    "from asyncio import Event\n",
    "from test_tube import Experiment\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.signal import medfilt\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from kornia.geometry.transform import Affine\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# import pytorchGLM.Utils.io_dict_to_hdf5 as ioh5\n",
    "# from pytorchGLM.Utils.utils import *\n",
    "# from pytorchGLM.Utils.params import *\n",
    "# from pytorchGLM.Utils.format_raw_data import *\n",
    "# from pytorchGLM.Utils.format_model_data import *\n",
    "# from pytorchGLM.main.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorchGLM as pglm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DataLoader',\n",
       " 'Dataset',\n",
       " 'FreeMovingEphysDataset',\n",
       " 'GroupShuffleSplit',\n",
       " 'LinearRegression',\n",
       " 'Path',\n",
       " 'Utils',\n",
       " '__author__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'add_colorbar',\n",
       " 'arg_parser',\n",
       " 'argparse',\n",
       " 'chain',\n",
       " 'check_path',\n",
       " 'cv2',\n",
       " 'discrete_cmap',\n",
       " 'format_data',\n",
       " 'format_model_data',\n",
       " 'format_pytorch_data',\n",
       " 'format_raw_data',\n",
       " 'gc',\n",
       " 'get_freer_gpu',\n",
       " 'get_modeltype',\n",
       " 'h5load',\n",
       " 'h5store',\n",
       " 'interp1d',\n",
       " 'interp_nans',\n",
       " 'interp_raw_data',\n",
       " 'io_dict_to_hdf5',\n",
       " 'ioh5',\n",
       " 'load_Kfold_data',\n",
       " 'load_aligned_data',\n",
       " 'load_model',\n",
       " 'load_params',\n",
       " 'main',\n",
       " 'make_network_config',\n",
       " 'medfilt',\n",
       " 'nan_helper',\n",
       " 'nanxcorr',\n",
       " 'nn',\n",
       " 'normimgs',\n",
       " 'np',\n",
       " 'optim',\n",
       " 'os',\n",
       " 'params',\n",
       " 'pd',\n",
       " 'plt',\n",
       " 'setup_model_training',\n",
       " 'shuffle',\n",
       " 'sizeof_fmt',\n",
       " 'str_to_bool',\n",
       " 'time',\n",
       " 'torch',\n",
       " 'tqdm',\n",
       " 'tune',\n",
       " 'utils',\n",
       " 'warnings',\n",
       " 'xr',\n",
       " 'yaml']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pglm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_ani': '070921/J553RT',\n",
       " 'base_dir': '~/Research/SensoryMotorPred_Data/Testing',\n",
       " 'fig_dir': '~/Research/SensoryMotorPred_Data/FigTesting',\n",
       " 'data_dir': '~/Goeppert/nlab-nas/Dylan/freely_moving_ephys/ephys_recordings/',\n",
       " 'model_dt': 0.05,\n",
       " 'ds_vid': 4,\n",
       " 'Kfold': 0,\n",
       " 'ModRun': '1',\n",
       " 'Nepochs': 10,\n",
       " 'load_ray': False,\n",
       " 'do_norm': True,\n",
       " 'crop_input': True,\n",
       " 'free_move': True,\n",
       " 'thresh_cells': True,\n",
       " 'fm_dark': False,\n",
       " 'NoL1': False,\n",
       " 'NoL2': False,\n",
       " 'NoShifter': False,\n",
       " 'do_shuffle': False,\n",
       " 'use_spdpup': False,\n",
       " 'only_spdpup': False,\n",
       " 'train_shifter': False,\n",
       " 'shifter_5050': False,\n",
       " 'shifter_5050_run': False,\n",
       " 'EyeHead_only': False,\n",
       " 'EyeHead_only_run': False,\n",
       " 'SimRF': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pglm.arg_parser(jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Parameters:\n",
    "- model_dt:     (float) size of time bins in seconds\n",
    "- date_ani:     (str) date and animal ID\n",
    "- base_dir:     (str) base directory\n",
    "- save_dir:     (str) directory where processed data is going to be saved\n",
    "- data_dir:     (str) directory where raw data is held\n",
    "- downsamp_vid: (int) factor videos are downsampled by\n",
    "- lag_list:     (list) which timesteps to include in fits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input arguments\n",
    "args = pglm.arg_parser(jupyter=True)\n",
    "\n",
    "dates_all = ['070921/J553RT' ,'101521/J559NC','102821/J570LT','110421/J569LT'] #,'122021/J581RT','020422/J577RT'] # '102621/J558NC' '062921/G6HCK1ALTRN',\n",
    "args['date_ani']        = dates_all[0]\n",
    "args['free_move']       = True\n",
    "args['train_shifter']   = True\n",
    "args['NoL1']            = False\n",
    "args['NoL2']            = False\n",
    "args['do_shuffle']      = False\n",
    "args['Nepochs']         = 10000\n",
    "\n",
    "\n",
    "ModelID = 1\n",
    "params, file_dict, exp = pglm.load_params(args,ModelID,file_dict=None,exp_dir_name=None,nKfold=0,debug=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['ModelID']=1\n",
    "params['position_vars'] = ['th','phi','pitch','roll']#,'speed','eyerad']\n",
    "params['train_shifter']=True\n",
    "\n",
    "\n",
    "data = load_aligned_data(file_dict, params, reprocess=False)\n",
    "data,train_idx_list,test_idx_list = format_data(data, params,do_norm=True,thresh_cells=True,cut_inactive=True)\n",
    "train_idx = train_idx_list[0]\n",
    "test_idx = test_idx_list[0]\n",
    "data = load_Kfold_data(data,params,train_idx,test_idx)\n",
    "xtr, xte, xtr_pos, xte_pos, ytr, yte, meanbias = format_pytorch_data(data,params,train_idx,test_idx)\n",
    "\n",
    "train_dataset = FreeMovingEphysDataset(xtr,xtr_pos,ytr)\n",
    "test_dataset  = FreeMovingEphysDataset(xte,xte_pos,yte)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=xtr.shape[0],num_workers=2,pin_memory=True,)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=xte.shape[0],num_workers=2,pin_memory=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid,pos,Y = next(iter(train_dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_config = make_network_config(params,single_trial=True)\n",
    "model = model_wrapper((network_config,ShifterNetwork))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShifterNetwork(\n",
       "  (Cell_NN): Sequential(\n",
       "    (0): Linear(in_features=1200, out_features=108, bias=True)\n",
       "  )\n",
       "  (activations): ModuleDict(\n",
       "    (SoftPlus): Softplus(beta=1, threshold=20)\n",
       "    (ReLU): ReLU()\n",
       "  )\n",
       "  (shifter_nn): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=20, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "    (2): Linear(in_features=20, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = next(iter(train_dataloader))\n",
    "vid,pos,y = minibatch\n",
    "vid,pos,y = vid.to(device),pos.to(device),y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(vid,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(list(params['save_dir'].glob('GLM_Pytorch_BestShift*'))[0])\n",
    "filename = list(params['save_dir'].glob('GLM_Pytorch_BestShift*'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_modeltype(params)\n",
    "network_config = make_network_config(params,single_trial=True)\n",
    "if params['train_shifter']:\n",
    "    model = model_wrapper((network_config,ShifterNetwork))\n",
    "elif (params['ModelID']==2) | (params['ModelID']==3):\n",
    "    model = model_wrapper((network_config,MixedNetwork))\n",
    "    model = load_model(model,params,filename,meanbias=meanbias)\n",
    "else:\n",
    "    model = model_wrapper((network_config,BaseModel))\n",
    "    model = load_model(model,params,filename,meanbias=meanbias)\n",
    "optimizer, scheduler = setup_model_training(model,params,network_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['ModelID']=1\n",
    "params['position_vars'] = ['th','phi','pitch','roll']#,'speed','eyerad']\n",
    "params['train_shifter']=True\n",
    "\n",
    "\n",
    "#####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_datasets(file_dict,params,single_trial=False):\n",
    "\n",
    "    data = load_aligned_data(file_dict, params, reprocess=False)\n",
    "    data,train_idx_list,test_idx_list = format_data(data, params,do_norm=True,thresh_cells=True,cut_inactive=True)\n",
    "    train_idx = train_idx_list[0]\n",
    "    test_idx = test_idx_list[0]\n",
    "    data = load_Kfold_data(data,params,train_idx,test_idx)\n",
    "    xtr, xte, xtr_pos, xte_pos, ytr, yte, meanbias = format_pytorch_data(data,params,train_idx,test_idx)\n",
    "    network_config = make_network_config(params,single_trial=single_trial)\n",
    "    with FileLock(params['save_model']/'data.lock'):\n",
    "        train_dataset = FreeMovingEphysDataset(xtr,xtr_pos,ytr)\n",
    "        test_dataset  = FreeMovingEphysDataset(xte,xte_pos,yte)\n",
    "    return train_dataset, test_dataset, network_config\n",
    "\n",
    "def train_network(network_config={},params={},train_dataset=None,test_dataset=None):\n",
    "    if params['train_shifter']:\n",
    "        model = model_wrapper((network_config,ShifterNetwork))\n",
    "    elif (params['ModelID']==2) | (params['ModelID']==3):\n",
    "        model = model_wrapper((network_config,MixedNetwork))\n",
    "        model = load_model(model,params,filename,meanbias=meanbias)\n",
    "    else:\n",
    "        model = model_wrapper((network_config,BaseModel))\n",
    "        model = load_model(model,params,filename,meanbias=meanbias)\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "            \n",
    "    model.to(device)\n",
    "\n",
    "    optimizer, scheduler = setup_model_training(model,params,network_config)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=len(train_dataset), num_workers=2, pin_memory=True,)\n",
    "    test_dataloader  = DataLoader(test_dataset,  batch_size=len(test_dataset),  num_workers=2, pin_memory=True,)\n",
    "\n",
    "    tloss_trace = torch.zeros((params['Nepochs'], network_config['Ncells']), dtype=torch.float)\n",
    "    vloss_trace = torch.zeros((params['Nepochs'], network_config['Ncells']), dtype=torch.float)\n",
    "\n",
    "    for epoch in (range(params['Nepochs'])):  # loop over the dataset multiple times\n",
    "        for i, minibatch in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; minibatch is a list of [vid, pos, y]\n",
    "            vid,pos,y = minibatch\n",
    "            vid,pos,y = vid.to(device),pos.to(device),y.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(vid,pos)\n",
    "            loss = model.loss(outputs, y)\n",
    "            loss.backward(torch.ones_like(loss))\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        tloss_trace[epoch] = loss.detach().cpu()\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Validation loss\n",
    "        for i, minibatch in enumerate(test_dataloader, 0):\n",
    "            with torch.no_grad():\n",
    "                # get the inputs; minibatch is a list of [vid, pos, y]\n",
    "                vid,pos,y = minibatch\n",
    "                vid,pos,y = vid.to(device),pos.to(device),y.to(device)\n",
    "                outputs = model(vid,pos)\n",
    "                loss = model.loss(outputs, y)\n",
    "                vloss_trace[epoch] = loss.detach().cpu()\n",
    "\n",
    "    # Here we save a checkpoint. It is automatically registered with\n",
    "    # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "    # API in future iterations.\n",
    "    model_name = 'GLM_{}_ModelID{:d}_dt{:03d}_T{:02d}_NB{}_{}.pt'.format(params['model_type'], params['ModelID'],int(params['model_dt']*1000), params['nt_glm_lag'], params['Nepochs'],session.get_trial_name())\n",
    "    torch.save((model.state_dict(), optimizer.state_dict()), params['save_model']/ model_name)\n",
    "    checkpoint = Checkpoint.from_dict({'step':epoch})\n",
    "    # session.report({\"avg_loss\": float(torch.mean(vloss_trace[-1],dim=-1).numpy())})\n",
    "    session.report({'avg_loss':float(torch.mean(vloss_trace[-1],dim=-1).numpy())}, checkpoint=checkpoint)\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    # return dict(avg_loss=float(torch.mean(vloss_trace[-1],dim=-1).numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pytorchGLM' has no attribute 'load_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb Cell 23\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bseuss/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m params \u001b[39m=\u001b[39m pglm\u001b[39m.\u001b[39mget_modeltype(params)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bseuss/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mNepochs\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bseuss/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m train_dataset, test_dataset, network_config \u001b[39m=\u001b[39m pglm\u001b[39m.\u001b[39;49mload_datasets(file_dict,params,single_trial\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pytorchGLM' has no attribute 'load_datasets'"
     ]
    }
   ],
   "source": [
    "params = pglm.get_modeltype(params)\n",
    "params['Nepochs'] = 10\n",
    "train_dataset, test_dataset, network_config = pglm.load_datasets(file_dict,params,single_trial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 02:40:09,396\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-09 02:40:43</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:32.46        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.1/125.8 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/1 GPUs, 0.0/71.38 GiB heap, 0.0/34.58 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  L2_lambda</th><th style=\"text-align: right;\">  L2_lambda_m</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  avg_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_network_fdf98_00000</td><td>TERMINATED</td><td>184.171.84.86:4193152</td><td style=\"text-align: right;\">       0.01</td><td style=\"text-align: right;\">         0.01</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.5794</td><td style=\"text-align: right;\">   1.03623</td></tr>\n",
       "<tr><td>train_network_fdf98_00001</td><td>TERMINATED</td><td>184.171.84.86:4193256</td><td style=\"text-align: right;\">    1000   </td><td style=\"text-align: right;\">         0.01</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3057</td><td style=\"text-align: right;\">   1.11026</td></tr>\n",
       "<tr><td>train_network_fdf98_00002</td><td>TERMINATED</td><td>184.171.84.86:4193152</td><td style=\"text-align: right;\">       0.01</td><td style=\"text-align: right;\">      1000   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.4374</td><td style=\"text-align: right;\">   1.03299</td></tr>\n",
       "<tr><td>train_network_fdf98_00003</td><td>TERMINATED</td><td>184.171.84.86:4193256</td><td style=\"text-align: right;\">    1000   </td><td style=\"text-align: right;\">      1000   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.5793</td><td style=\"text-align: right;\">   1.08691</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]0m \n",
      " 10%|█         | 1/10 [00:03<00:29,  3.30s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]0m \n",
      " 20%|██        | 2/10 [00:04<00:16,  2.03s/it]\n",
      " 30%|███       | 3/10 [00:05<00:11,  1.65s/it]\n",
      " 10%|█         | 1/10 [00:02<00:25,  2.84s/it]\n",
      " 40%|████      | 4/10 [00:06<00:08,  1.43s/it]\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.79s/it]\n",
      " 50%|█████     | 5/10 [00:07<00:06,  1.31s/it]\n",
      " 30%|███       | 3/10 [00:04<00:09,  1.41s/it]\n",
      " 60%|██████    | 6/10 [00:08<00:04,  1.23s/it]\n",
      " 40%|████      | 4/10 [00:05<00:07,  1.24s/it]\n",
      " 70%|███████   | 7/10 [00:10<00:03,  1.22s/it]\n",
      " 50%|█████     | 5/10 [00:06<00:05,  1.15s/it]\n",
      " 60%|██████    | 6/10 [00:07<00:04,  1.12s/it]\n",
      " 80%|████████  | 8/10 [00:11<00:02,  1.22s/it]\n",
      " 90%|█████████ | 9/10 [00:12<00:01,  1.17s/it]\n",
      " 70%|███████   | 7/10 [00:08<00:03,  1.11s/it]\n",
      " 80%|████████  | 8/10 [00:10<00:02,  1.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  avg_loss</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_network_fdf98_00000</td><td style=\"text-align: right;\">   1.03623</td><td>True               </td></tr>\n",
       "<tr><td>train_network_fdf98_00001</td><td style=\"text-align: right;\">   1.11026</td><td>True               </td></tr>\n",
       "<tr><td>train_network_fdf98_00002</td><td style=\"text-align: right;\">   1.03299</td><td>True               </td></tr>\n",
       "<tr><td>train_network_fdf98_00003</td><td style=\"text-align: right;\">   1.08691</td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_network pid=4193152)\u001b[0m Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]0m \n",
      " 90%|█████████ | 9/10 [00:11<00:01,  1.07s/it]\n",
      " 10%|█         | 1/10 [00:01<00:09,  1.11s/it]\n",
      "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_network pid=4193256)\u001b[0m Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]0m \n",
      " 20%|██        | 2/10 [00:02<00:08,  1.12s/it]\n",
      " 10%|█         | 1/10 [00:01<00:09,  1.08s/it]\n",
      " 30%|███       | 3/10 [00:03<00:07,  1.12s/it]\n",
      " 20%|██        | 2/10 [00:02<00:08,  1.04s/it]\n",
      " 40%|████      | 4/10 [00:04<00:06,  1.12s/it]\n",
      " 30%|███       | 3/10 [00:03<00:07,  1.02s/it]\n",
      " 50%|█████     | 5/10 [00:05<00:05,  1.13s/it]\n",
      " 40%|████      | 4/10 [00:04<00:06,  1.08s/it]\n",
      " 60%|██████    | 6/10 [00:06<00:04,  1.15s/it]\n",
      " 50%|█████     | 5/10 [00:05<00:05,  1.06s/it]\n",
      " 70%|███████   | 7/10 [00:07<00:03,  1.13s/it]\n",
      " 60%|██████    | 6/10 [00:06<00:04,  1.06s/it]\n",
      " 80%|████████  | 8/10 [00:09<00:02,  1.13s/it]\n",
      " 70%|███████   | 7/10 [00:07<00:03,  1.05s/it]\n",
      " 90%|█████████ | 9/10 [00:10<00:01,  1.11s/it]\n",
      " 80%|████████  | 8/10 [00:08<00:02,  1.04s/it]\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_network pid=4193152)\u001b[0m Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:09<00:01,  1.03s/it]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "2023-01-09 02:40:43,435\tINFO tune.py:762 -- Total run time: 32.64 seconds (32.45 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_network pid=4193256)\u001b[0m Finished Training\n",
      "Best trial config: {'in_features': 1200, 'Ncells': 108, 'shift_in': 3, 'shift_hidden': 20, 'shift_out': 3, 'LinMix': False, 'pos_features': 3, 'lr_shift': 0.01, 'lr_w': 0.001, 'lr_b': 0.001, 'lr_m': 0.001, 'L1_alpha': None, 'L1_alpham': None, 'L2_lambda': 0.01, 'L2_lambda_m': 1000.0}\n",
      "Best trial final validation loss: 1.032989501953125\n"
     ]
    }
   ],
   "source": [
    "sync_config = tune.SyncConfig()  # the default mode is to use use rsync\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train_network,params=params,train_dataset=train_dataset,test_dataset=test_dataset),\n",
    "        resources={\"cpu\": 2, \"gpu\": .5}),\n",
    "    tune_config=tune.TuneConfig(metric=\"avg_loss\",mode=\"min\",),\n",
    "    param_space=network_config,\n",
    "    run_config=air.RunConfig(local_dir=params['save_model'], name=\"test_experiment\",sync_config=sync_config,verbose=2)\n",
    ")\n",
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result(\"avg_loss\", \"min\")\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"avg_loss\"]))\n",
    "df = results.get_dataframe()\n",
    "df.to_hdf(params['save_model']/'experiment_data.h5',key='df', mode='w')\n",
    "best_network = list(params['save_model'].glob('*{}.pt'.format(best_result.metrics['trial_id'])))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((model.state_dict(), optimizer.state_dict()), params['save_model']/ \"checkpoint.pt\")\n",
    "checkpoint = Checkpoint.from_directory(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.01\n",
       "1       0.01\n",
       "2    1000.00\n",
       "3    1000.00\n",
       "Name: config/L2_lambda_m, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_dataframe()['config/L2_lambda_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 17:46:32,320\tWARNING experiment_analysis.py:627 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: loss. This means that no trial has reported this metric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb Cell 27\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bseuss/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m results\u001b[39m.\u001b[39;49mget_best_result(metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m,mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m,filter_nan_and_inf\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchGLM/lib/python3.8/site-packages/ray/tune/result_grid.py:134\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    123\u001b[0m     error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo best trial found for the given metric: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experiment_analysis\u001b[39m.\u001b[39mdefault_metric\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis means that no trial has reported this metric\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[39mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    132\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: loss. This means that no trial has reported this metric."
     ]
    }
   ],
   "source": [
    "results.get_best_result(metric='loss',mode='min',filter_nan_and_inf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 18:39:35,898\tWARNING experiment_analysis.py:627 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb Cell 29\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bseuss/home/seuss/Research/MyRepos/pytorchGLM2/Testing02.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m results\u001b[39m.\u001b[39;49mget_best_result()\u001b[39m.\u001b[39mmetrics_dataframe()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchGLM/lib/python3.8/site-packages/ray/tune/result_grid.py:134\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    123\u001b[0m     error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo best trial found for the given metric: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experiment_analysis\u001b[39m.\u001b[39mdefault_metric\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis means that no trial has reported this metric\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[39mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    132\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "results.get_best_result().metrics_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot_units: (128,)\n",
      "Good_units: (108,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b802aec8c7a4c58b38bc35b0c3c2fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = get_modeltype(params)\n",
    "train_dataset, test_dataset, network_config = load_datasets(file_dict,params,single_trial=True)\n",
    "\n",
    "if params['train_shifter']:\n",
    "    model = model_wrapper((network_config,ShifterNetwork))\n",
    "elif (params['ModelID']==2) | (params['ModelID']==3):\n",
    "    model = model_wrapper((network_config,MixedNetwork))\n",
    "    model = load_model(model,params,filename,meanbias=meanbias)\n",
    "else:\n",
    "    model = model_wrapper((network_config,BaseModel))\n",
    "    model = load_model(model,params,filename,meanbias=meanbias)\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "optimizer, scheduler = setup_model_training(model,params,network_config)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=len(train_dataset), num_workers=2, pin_memory=True,)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=len(test_dataset),  num_workers=2, pin_memory=True,)\n",
    "params['Nepochs']=10\n",
    "\n",
    "tloss_trace = torch.zeros((params['Nepochs'], network_config['Ncells']), dtype=torch.float)\n",
    "vloss_trace = torch.zeros((params['Nepochs'], network_config['Ncells']), dtype=torch.float)\n",
    "\n",
    "for epoch in tqdm(range(params['Nepochs'])):  # loop over the dataset multiple times\n",
    "    for i, minibatch in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; minibatch is a list of [vid, pos, y]\n",
    "        vid,pos,y = minibatch\n",
    "        vid,pos,y = vid.to(device),pos.to(device),y.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(vid,pos)\n",
    "        loss = model.loss(outputs, y)\n",
    "        loss.backward(torch.ones_like(loss))\n",
    "        optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    tloss_trace[epoch] = loss.detach().cpu()\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid,pos,Y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3496b118a4d22d6a6f5485f441160c3e17db178642e3548badf1988c7bf383fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
